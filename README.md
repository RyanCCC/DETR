# DETR Tensorflow

[DETR : End-to-End Object Detection with Transformers](https://arxiv.org/pdf/2005.12872.pdf):å°†`Transformer`åº”ç”¨äºç›®æ ‡æ£€æµ‹ã€‚Pytorchç‰ˆæœ¬çš„å®ç°ï¼š[facebookresearch/detr](https://github.com/facebookresearch/detr)ã€‚æœ¬ä»“åº“åŸºäºTensorflowå®ç°DETRï¼ŒåŒ…æ‹¬è®­ç»ƒä»£ç ã€æ¨ç†ä»£ç ä»¥åŠ`finetune`ä»£ç ã€‚ä¸»è¦å‚è€ƒï¼š[
detr-tensorflow](https://github.com/Visual-Behavior/detr-tensorflow)ã€‚DETRç½‘ç»œç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š

![](./src/detr.png)

## é¡¹ç›®æ¶æ„
```
â”œâ”€dataï¼šæ•°æ®é›†åŸºæœ¬æ“ä½œ
â”œâ”€detrï¼šDETRç½‘ç»œå®ç°
â”‚  â”œâ”€lossï¼šæŸå¤±å‡½æ•°
â”‚  â””â”€networksï¼šä¸»è¦ç½‘ç»œå®ç°ä»£ç 
â”œâ”€loggerï¼šæ—¥å¿—è„šæœ¬
â”œâ”€notebooksï¼šä»‹ç»è¯´æ˜çš„Jupyter notebook
â””â”€srcï¼šä¸€äº›èµ„æºæ–‡ä»¶ï¼Œå¦‚readmeçš„å›¾åƒ
```

## ä»‹ç»è¯´æ˜

- âœ [DETR Tensorflow - How to load a dataset.ipynb](https://github.com/RyanCCC/DETR/blob/main/notebooks/How%20to%20load%20a%20dataset.ipynb)
- âœ [DETR Tensorflow - Finetuning tutorial.ipynb](https://github.com/RyanCCC/DETR/blob/main/notebooks/DETR%20Tensorflow%20-%20%20Finetuning%20tutorial.ipynb)
- âœ [DETR Tensorflow - How to setup a custom dataset.ipynb](https://github.com/RyanCCC/DETR/blob/main/notebooks/DETR%20Tensorflow%20-%20%20How%20to%20setup%20a%20custom%20dataset.ipynb)
- ğŸš€ [Finetuning DETR on Tensorflow - A step by step guide](https://wandb.ai/thibault-neveu/detr-tensorflow-log/reports/Finetuning-DETR-on-Tensorflow-A-step-by-step-tutorial--VmlldzozOTYyNzQ)


## æ¨¡å‹è®­ç»ƒ

è®­ç»ƒcocoæ•°æ®é›†ï¼Œæ•°æ®æ–‡ä»¶æ¶æ„å¦‚ä¸‹ï¼š

- data_dirï¼šcocoæ•°æ®é›†æ ¹ç›®å½•
- img_dirï¼šè®­ç»ƒé›†å’ŒéªŒè¯é›†å›¾åƒæ–‡ä»¶å¤¹
- ann_fileï¼šè®­ç»ƒé›†å’ŒéªŒè¯é›†å›¾åƒæ ‡æ³¨æ–‡ä»¶å¤¹

æ‰§è¡Œå‘½ä»¤ï¼š```python train_coco.py --data_dir /path/to/COCO --batch_size 8  --target_batch 32 --log```ã€‚

## æ¨¡å‹å¾®è°ƒ

å¾®è°ƒçš„åŸºæœ¬æµç¨‹ï¼š
```python
# Load the pretrained model
detr = get_detr_model(config, include_top=False, nb_class=3, weights="detr", num_decoder_layers=6, num_encoder_layers=6)
detr.summary()

# Load your dataset
train_dt, class_names = load_tfcsv_dataset(config, config.batch_size, augmentation=True)

# Setup the optimziers and the trainable variables
optimzers = setup_optimizers(detr, config)

# Train the model
training.fit(detr, train_dt, optimzers, config, epoch_nb, class_names)
```

### Pacal VOCæ•°æ®é›†

ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

- data_dirï¼šæ•°æ®é›†æ ¹ç›®å½•
- img_dirï¼šæ•°æ®é›†çš„å›¾åƒ
- ann_fileï¼šæ•°æ®é›†æ ‡æ³¨æ–‡ä»¶

æ‰§è¡Œå‘½ä»¤ï¼š```python finetune_voc.py --data_dir /home/thibault/data/VOCdevkit/VOC2012 --img_dir JPEGImages --ann_dir Annotations --batch_size 8 --target_batch 32  --log```

### hardhatcsvæ•°æ®é›†

ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

- data_dirï¼šæ•°æ®é›†æ ¹ç›®å½•
- img_dirï¼šæ•°æ®é›†çš„å›¾åƒ
- ann_fileï¼šæ•°æ®é›†æ ‡æ³¨æ–‡ä»¶

æ‰§è¡Œå‘½ä»¤ï¼š```python  finetune_hardhat.py --data_dir /home/thibault/data/hardhat --batch_size 8 --target_batch 32 --log```

## æ¨¡å‹è¯„ä¼°

æµ‹è¯•é›†æ•°æ®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

- data_dirï¼šæµ‹è¯•é›†æ ¹ç›®å½•
- img_dirï¼šæµ‹è¯•é›†çš„å›¾åƒ
- ann_fileï¼šæµ‹è¯•é›†Ground True

æ‰§è¡Œå‘½ä»¤:```python eval.py --data_dir /path/to/coco/dataset --img_dir val2017 --ann_file annotations/instances_val2017.json```

