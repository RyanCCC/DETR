{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR : How to load a dataset\n",
    "\n",
    "This tutorial aims to introduce you to the datasets format you can use to train or finetune a model on DETR.\n",
    "\n",
    "    - 1. Dataset pipeline and outputs\n",
    "    - 2. Coco Dataset\n",
    "    - 3. Voc Dataset\n",
    "    - 4. Tensorflow csv Dataset\n",
    "\n",
    "<img src=\"../src/datasetsupport.png\"></img>\n",
    "\n",
    "\n",
    "## 1. Dataset pipeline and outputs\n",
    "\n",
    "Any implemented dataset on this repository run the following pipeline\n",
    "\n",
    "- **Dataset specific** loading: The first step is specific to a dataset. This repository provides method to load dataset that follow the coco, voc or Tensorflow csv format. If you want to support an other format you can considere to implement your own pipeline following our tutorial (DETR Tensorflow - How to setup a custom dataset.ipynb) or post a feature request on the github. \n",
    "\n",
    "- **DETR transformations/augmentations**: the provided methods apply the transformations and augmentations needed on your data\n",
    "- **Image normalization**: The pipeline will also normalizations your image before to call return the final data\n",
    "- **Tensorflow Dataset**: Once the dataset is ready, the method setup a Tensorflow Dataset and return an iterator that can be used to train or finetune DETR.\n",
    "\n",
    "<img src=\"../src/data-pipeline.png\"></img>\n",
    "\n",
    "\n",
    "The datasets outputs:\n",
    "    \n",
    "- **images** of shape (batch_size, height, width, 3) where height and width are constant defined in your training config.\n",
    "- **target bbox** (batch_size, 100, 4). All target bbox are padded to fixed size and comes up with an header to keep track of the number of real bbox. This is usefull later on during the training on Tensorflow. Note that this header is temporary and should be remove in upcoming versions by ragged tensors\n",
    "- **target class** (batch, size, 100, 1) The class id of each bbox. Like the bbox, the target class are padded for training purposes.\n",
    "\n",
    "\n",
    "## Coco Dataset\n",
    "\n",
    "If you're dataset follow the Coco Dataset format, then detr_tf provide you with a method to automatically load your dataset. Any coco dataset is made of at least one image's directory and one json annotation file following the coco instance json format.\n",
    "\n",
    "### Training config for a coco dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Set the path to detr_tf\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data import load_coco_dataset\n",
    "from detr.training_config import TrainingConfig, DataConfig\n",
    "\n",
    "class MyConfig(TrainingConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.data_dir = \"/path/to/coco_format/dataset\"\n",
    "        self.data = DataConfig(data_dir=self.data_dir, img_dir=\"val2017\", ann_file=\"annotations/instances_val2017.json\")\n",
    "        self.batch_size = 1\n",
    "\n",
    "config = MyConfig()\n",
    "iterator, class_names = load_coco_dataset(config, config.batch_size, augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset returns an iterator that you can use to train your model along with the list of class in the dataset expand with the background class.\n",
    "\n",
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr.inference import numpy_bbox_to_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for images, target_bbox, target_class in iterator:\n",
    "    print(\"images.shape\", images.shape)\n",
    "    print(\"target_bbox.shape\", target_bbox.shape)\n",
    "    print(\"target_class.shape\", target_class.shape)\n",
    "\n",
    "    # Plot image\n",
    "    image = numpy_bbox_to_image(\n",
    "        np.array(images[0]),\n",
    "        np.array(target_bbox[0]),\n",
    "        labels=np.array(target_class[0]),\n",
    "        scores=None,\n",
    "        class_name=class_names,\n",
    "        config=config\n",
    "    )\n",
    "    plt.imshow(image)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voc Dataset\n",
    "\n",
    "If you're dataset follow the Voc Dataset format, then detr_tf provide you with a method to automaticly load your dataset. A voc dataset is at least made of one image folder and one xml folder (XMLs and Images can be stored in the same directory)\n",
    "\n",
    "### ### Training config for a VOC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '/path/to/voc_dataset/JPEGImages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31404\\2330161729.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_voc_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Code\\MyGithub\\DETR\\data\\voc.py\u001b[0m in \u001b[0;36mload_voc_dataset\u001b[1;34m(config, batch_size, augmentation, ann_dir, ann_file, img_dir)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0manno_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mann_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# ids lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# Retrieve the class names in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: '/path/to/voc_dataset/JPEGImages'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Set the path to detr_tf\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data import load_voc_dataset\n",
    "from detr.training_config import TrainingConfig, DataConfig\n",
    "\n",
    "class MyConfig(TrainingConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data_dir = r\"D:\\Code\\AGCIMAIGit\\Dataset_Object_Detection\\village\"\n",
    "        self.data = DataConfig(data_dir=self.data_dir, img_dir=\"JPEGImages\", ann_dir=\"Annotations\")\n",
    "        self.batch_size = 1\n",
    "\n",
    "config = MyConfig()\n",
    "iterator, class_names = load_voc_dataset(config, config.batch_size, augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset returns an iterator that you can use to train your model along with the list of class in the dataset expand with the background class.\n",
    "\n",
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detr.inference import numpy_bbox_to_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for images, target_bbox, target_class in iterator:\n",
    "    print(\"images.shape\", images.shape)\n",
    "    print(\"target_bbox.shape\", target_bbox.shape)\n",
    "    print(\"target_class.shape\", target_class.shape)\n",
    "\n",
    "    # Plot image\n",
    "    image = numpy_bbox_to_image(\n",
    "        np.array(images[0]),\n",
    "        np.array(target_bbox[0]),\n",
    "        labels=np.array(target_class[0]),\n",
    "        scores=None,\n",
    "        class_name=class_names,\n",
    "        config=config\n",
    "    )\n",
    "    plt.imshow(image)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow csv Dataset\n",
    "\n",
    "If you're dataset follow the Tensorflow csv format, then detr_tf provide you with a method to automatically load your dataset. Any tfcsv dataset is made of at least one image's directory and one csv annotation file following the tensorflow csv format object detection format.\n",
    " \n",
    "\n",
    "\n",
    "### Training config for a Tensorflow csv Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Set the path to detr_tf\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data import load_tfcsv_dataset\n",
    "from detr.training_config import TrainingConfig, DataConfig\n",
    "\n",
    "class MyConfig(TrainingConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data_dir = \"/path/to/tfcsv/dataset/\"\n",
    "        self.data = DataConfig(data_dir=self.data_dir, img_dir=\"test\", ann_file=\"test/_annotations.csv\")\n",
    "        self.batch_size = 1\n",
    "\n",
    "config = MyConfig()\n",
    "iterator, class_names = load_tfcsv_dataset(config, config.batch_size, augmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset returns an iterator that you can use to train your model along with the list of class in the dataset expand with the background class.\n",
    "\n",
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr.inference import numpy_bbox_to_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for images, target_bbox, target_class in iterator:\n",
    "    print(\"images.shape\", images.shape)\n",
    "    print(\"target_bbox.shape\", target_bbox.shape)\n",
    "    print(\"target_class.shape\", target_class.shape)\n",
    "\n",
    "    # Plot image\n",
    "    image = numpy_bbox_to_image(\n",
    "        np.array(images[0]),\n",
    "        np.array(target_bbox[0]),\n",
    "        labels=np.array(target_class[0]),\n",
    "        scores=None,\n",
    "        class_name=class_names,\n",
    "        config=config\n",
    "    )\n",
    "    plt.imshow(image)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6c6e9ad919e43ea991096268ac22857d89ff5f05140928bb8d03f6bb8d6e7c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
